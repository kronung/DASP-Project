{"EMNLP2019": {"name": "", "location": "", "datetime": "", "submission_deadlines": [{"name": "", "date": ""}], "topics": [], "organizers": [], "papers": [{"authors": [], "title": "", "link": ""}], "tutorials": [{"title": "[T1] Dive into Deep Learning for Natural Language Processing", "authors": ["Haibin Lin", "Xingjian Shi", "Leonard Lausen", "Aston Zhang", "He He", "Sheng Zha", "Alexander Smola"], "abstract": "Deep learning has become the dominant approach to NLP problems, especially when applied on large scale corpora. Recent progress on unsupervised pre-training techniques such as BERT, ELMo, GPT-2, and language modeling in general, when applied on large corpora, is shown to be effective in improving a wide variety of downstream tasks. These techniques push the limits of available hardware, requiring specialized frameworks optimized for GPU, ASIC, and distributed cloud-based training. A few complexities pose challenges to scale these models and algorithms effectively. Compared to other areas where deep learning is applied, these NLP models contain a variety of moving parts: text normalization and tokenization, word representation at subword-level and word-level, variable-length models such as RNN and attention, and sequential decoder based on beam search, among others. In this hands-on tutorial, we take a closer look at the challenges from these complexities and see how with proper tooling with Apache MXNet and GluonNLP, we can overcome these challenges and achieve state-of-the-art results for real-world problems. GluonNLP is a powerful new toolkit that combines MXNet\u2019s speed, the flexibility of Gluon, and an extensive new library automating the most laborious aspects of deep learning for NLP.", "datetime": "Sunday, November 3 2019, 09:00 \u2013 12:30, 14:00 \u2013 17:30", "location": "AWE 201B\u2013C", "link": null}, {"title": "[T2] Processing and Understanding Mixed Language Data", "authors": ["Monojit Choudhury", "Kalika Bali"], "abstract": "Multilingual communities exhibit code-mixing, that is, mixing of two or more socially stable languages in a single conversation, sometimes even in a single utterance. This phenomenon has been widely studied by linguists and interaction scientists in the spoken language of such communities. However, with the prevalence of social media and other informal interactive platforms, code-switching is now also ubiquitously observed in user-generated text. As multilingual communities are more the norm from a global perspective, it becomes essential that code-switched text and speech are adequately handled by language technologies and NUIs. Code-mixing is extremely prevalent in all multilingual societies. Current studies have shown that as much as 20% of user generated content from some geographies, like South Asia, parts of Europe, and Singapore, are code-mixed. Thus, it is very important to handle code-mixed content as a part of NLP systems and applications for these geographies. In the past 5 years, there has been an active interest in computational models for code-mixing with a substantive research outcome in terms of publications, datasets and systems. However, it is not easy to find a single point of access for a complete and coherent overview of the research. This tutorial is expecting to fill this gap and provide new researchers in the area with a foundation in both linguistic and computational aspects of code-mixing. We hope that this then becomes a starting point for those who wish to pursue research, design, development and deployment of code-mixed systems in multilingual societies.", "datetime": "Sunday, November 3 2019, 09:00 \u2013 12:30", "location": "Marriott Ballroom B\u2013C", "link": null}, {"title": "[T3] Data Collection and End-to-End Learning for Conversational AI", "authors": ["Tsung-Hsien Wen", "Pei-Hao Su", "Pawe\u0142 Budzianowski", "I\u00f1igo Casanueva", "Ivan Vuli\u0107"], "abstract": "A fundamental long-term goal of conversational AI is to merge two main dialogue system paradigms into a standalone multi-purpose system. Such a system should be capable of conversing about arbitrary topics (Paradigm 1: open-domain dialogue systems), and simultaneously assist humans with completing a wide range of tasks with well-defined semantics such as restaurant search and booking, customer service applications, or ticket bookings (Paradigm 2: task-based dialogue systems). The recent developmental leaps in conversational AI technology are undoubtedly linked to more and more sophisticated deep learning algorithms that capture patterns in increasing amounts of data generated by various data collection mechanisms. The goal of this tutorial is therefore twofold. First, it aims at familiarising the research community with the recent advances in algorithmic design of statistical dialogue systems for both open-domain and task-based dialogue paradigms. The focus of the tutorial is on recently introduced end-to-end learning for dialogue systems and their relation to more common modular systems. In theory, learning end-to-end from data offers seamless and unprecedented portability of dialogue systems to a wide spectrum of tasks and languages. From a practical point of view, there are still plenty of research challenges and opportunities remaining: in this tutorial we analyse this gap between theory and practice, and introduce the research community with the main advantages as well as with key practical limitations of current end-to-end dialogue learning. The critical requirement of each statistical dialogue system is the data at hand. The system cannot provide assistance for the task without having appropriate task-related data to learn from. Therefore, the second major goal of this tutorial is to provide a comprehensive overview of the current approaches to data collection for dialogue, and analyse the current gaps and challenges with diverse data collection protocols, as well as their relation to and current limitations of data-driven end-to-end dialogue modeling. We will again analyse this relation and limitations both from research and industry perspective, and provide key insights on the application of state-of-the-art methodology into industry-scale conversational AI systems.", "datetime": "Sunday, November 3 2019, 14:00 \u2013 17:30", "location": "Marriott Ballroom B\u2013C", "link": null}, {"title": "[T4] Bias and Fairness in Natural Language Processing", "authors": ["Kai-Wei Chang", "Margaret Mitchell", "Vicente Ordonez"], "abstract": "Recent advances in data-driven machine learning techniques (e.g., deep neural networks) have revolutionized many natural language processing applications. These approaches automatically learn how to make decisions based on the statistics and diagnostic information from large amounts of training data. Despite the remarkable accuracy of machine learning in various applications, learning algorithms run the risk of relying on societal biases encoded in the training data to make predictions. This often occurs even when gender and ethnicity information is not explicitly provided to the system because learning algorithms are able to discover implicit associations between individuals and their demographic information based on other variables such as names, titles, home addresses, etc. Therefore, machine learning algorithms risk potentially encouraging unfair and discriminatory decision making and raise serious privacy concerns. Without properly quantifying and reducing the reliance on such correlations, broad adoption of these models might have the undesirable effect of magnifying harmful stereotypes or implicit biases that rely on sensitive demographic attributes. In this tutorial, we will review the history of bias and fairness studies in machine learning and language processing and present recent community effort in quantifying and mitigating bias in natural language processing models for a wide spectrum of tasks, including word embeddings, co-reference resolution, machine translation, and vision-and-language tasks. In particular, we will focus on the following topics:", "datetime": "Monday November 4 2019, 09:00 \u2013 12:30", "location": "Marriott Ballroom B\u2013C", "link": null}, {"title": "[T5] Discreteness in Neural Natural Language Processing", "authors": ["Lili Mou", "Hao Zhou", "Lei Li"], "abstract": "This tutorial provides a comprehensive guide to the process of discreteness in neural NLP. As a gentle start, we will briefly introduce the background of deep learning based NLP, where we point out the ubiquitous discreteness of natural language and its challenges in neural information processing. Particularly, we will focus on how such discreteness plays a role in the input space, the latent space, and the output space of a neural network. In each part, we will provide examples, discuss machine learning techniques, as well as demonstrate NLP applications.", "datetime": "Monday November 4 2019, 09:00 \u2013 12:30", "location": "AWE Hall 2B \u2013 Part. 2", "link": null}, {"title": "[T6] Graph-based Deep Learning in Natural Language Processing", "authors": ["Shikhar Vashishth", "Naganand Yadati", "Partha Talukdar"], "abstract": "This tutorial aims to introduce recent advances in graph-based deep learning techniques such as Graph Convolutional Networks (GCNs) for Natural Language Processing (NLP). It provides a brief introduction to deep learning methods on non-Euclidean domains such as graphs and justifies their relevance in NLP. It then covers recent advances in applying graph-based deep learning methods for various NLP tasks, such as semantic role labeling, machine translation, relationship extraction, and many more.", "datetime": "Monday November 4 2019, 14:00 \u2013 17:30", "location": "AWE Hall 2B \u2013 Part. 2", "link": null}, {"title": "[T7] Semantic Specialization of Distributional Word Vectors", "authors": ["Goran Glava\u015b", "Edoardo Maria Ponti", "Ivan Vuli\u0107"], "abstract": "Distributional word vectors have become an indispensable component of most state-of-art NLP models. As a major artefact of the underlying distributional hypothesis, distributional word vector spaces conflate various paradigmatic and syntagmatic lexico-semantic relations. For example, relations such as synonymy/similarity (e.g., car-automobile) or lexical entailment (e.g., car-vehicle) often cannot be distinguished from antonymy (e.g., black-white), meronymy (e.g., car-wheel) or broader thematic relatedness (e.g., car-driver) based on the distances in the distributional vector space. This inherent property of distributional spaces often harms performance in downstream applications, since different lexico-semantic relations support different classes of NLP applications. For instance, Semantic Similarity provides guidance for Paraphrasing, Dialogue State Tracking, and Text Simplification, Lexical Entailment supports Natural Language Inference and Taxonomy Induction, whereas broader thematic relatedness yields gains for Named Entity Recognition, Parsing, and Text Classification and Retrieval. A plethora of methods have been proposed to emphasize specific lexico-semantic relations in a reshaped (i.e., specialized) vector space. A common solution is to move beyond purely unsupervised word representation learning and include external lexico-semantic knowledge, in a process commonly referred to as semantic specialization. In this tutorial, we provide a thorough overview of specialization methods, covering: 1) joint specialization methods, which augment distributional learning objectives with external linguistic constraints, 2) post-processing retrofitting models, which fine-tune pre-trained distributional vectors to better reflect external linguistic constraints, and 3) the most recently proposed post-specialization methods that generalize the perturbations of the post-processing methods to the whole distributional space. In addition to providing a comprehensive overview of specialization methods, we will introduce the most recent developments, such as (among others): handling asymmetric relations (e.g., hypernymy-hyponymy) in Euclidean and hyperbolic spaces by accounting for vector magnitude as well as for vector distance; cross-lingual transfer of semantic specialization for languages without external lexico-semantic resources; downstream effects of specializing distributional vector spaces; injecting external knowledge into unsupervised pretraining architectures such as ELMo or BERT.", "datetime": "Monday November 4 2019, 14:00 \u2013 17:30", "location": "Marriott Ballroom B\u2013C", "link": null}], "keynotes": [{"title": "Project Debater - how persuasive can a computer be?", "authors": "Noam Slonim (IBM Haifa Research Lab)", "abstract": "Project Debater is the first AI system that can meaningfully debate a human opponent. The system, an IBM Grand Challenge, is designed to build coherent, convincing speeches on its own, as well as provide rebuttals to the opponent\u2019s main arguments. In February 2019, Project Debater competed against Harish Natarajan, who holds the world record for most debate victories, in an event held in San Francisco that was broadcasted live world-wide. In this talk I will tell the story of Project Debater, from conception to a climatic final event, describe its underlying technology, and discuss how it can be leveraged for advancing decision making and critical thinking.", "datetime": "Tuesday, 5 November 2019, 09:00 \u2013 10:00", "location": "AWE Hall 2C", "link": null}, {"title": "Current Challenges in Computational Social Science", "authors": "Meeyoung Cha (KAIST)", "abstract": "Artificial intelligence (AI) is reshaping business and science. Computational social science is an interdisciplinary field that solves complex societal problems by adopting AI-driven methods, processes, algorithms, and systems on data of various forms. This talk will review some of the latest advances in the research that focuses on fake news and legal liability. I will first discuss the structural, temporal, and linguistic traits of fake news propagation. One emerging challenge here is the increasing use of automated bots to generate and propagate false information. I will also discuss the current issues on the legal liability of AI and robots, particularly on how to regulate them (e.g., moral machine, punishment gap). This talk will suggest new opportunities to tackle these problems.", "datetime": "Wednesday, 6 November 2019, 09:00 \u2013 10:00", "location": "AWE Hall 2C", "link": null}, {"title": "Curiosity-driven Journey into Neural Sequence Models", "authors": "Kyunghyun Cho (New York University)", "abstract": "In this talk, I take the audience on a tour of my earlier and recent experiences in building neural sequence models. I start from the earlier experience of using a recurrent net for sequence-to-sequence learning and talk about the attention mechanism. I discuss factors behind the success of these earlier approaches, and how these were embraced by the community even before they sota\u2019d. I then move on to more recent research direction in unconventional neural sequence models that automatically learn to decide on the order of generation.", "datetime": "Thursday, 7 November 2019, 09:00 \u2013 10:00", "location": "AWE Hall 2C", "link": null}], "workshops": [{"title": "[W1] CoNLL 2019 The Conference on Computational Natural Language Learning", "authors": null, "abstract": "The Conference on Computational Natural Language Learning is a top-tier conference, yearly organized by SIGNLL (ACL\u2019s Special Interest Group on Natural Language Learning).", "datetime": "Monday November 4 2019, 09:00 \u2013 17:35", "location": "AWE Hall 2B", "link": "http://www.conll.org"}, {"title": "[W2] FEVER The second workshop on Fact Extraction and VERification", "authors": null, "abstract": "The second workshop on Fact Extraction and VERification brings together researchers working on various tasks related to fact extraction and verification and also hosts the FEVER Challenge, an information verification shared task.", "datetime": "Monday November 3 2019, 09:00 \u2013 12:30", "location": "AWE 202", "link": "http://fever.ai"}, {"title": "[W3] DiscoMT19 Discourse in Machine Translation 2019", "authors": null, "abstract": "Discourse in Machine Translation 2019 focuses on language processing techniques, whether theoretically-inspired or empirical, which address one or more discourse-level phenomena in combination with MT or from a cross-lingual perspective.", "datetime": "Monday November 3 2019, 09:00 \u2013 12:30", "location": "AWE 201A", "link": "https://www.idiap.ch/workshop/DiscoMT"}, {"title": "[W4] LANTERN Beyond Vision and Language: Integrating Knowledge from the Real World", "authors": null, "abstract": "Beyond Vision and Language: Integrating Knowledge from the Real World aims to to bring together researchers from different disciplines but united by their adoption of techniques from machine learning, neuroscience, multi-agents, natural language processing, computer vision and psychology to interconnect language and vision by leveraging external knowledge provided by either fixed or environments.", "datetime": "Monday November 3 2019, 09:00 \u2013 12:30", "location": "AWE 201A", "link": "https://www.lantern.uni-saarland.de/"}, {"title": "[W5] MSR 2019 The second Workshop on Multilingual Surface Realization", "authors": null, "abstract": "The second Workshop on Multilingual Surface Realization aims at bringing together people who are interested in surface-oriented Natural Language Generation problems such as word order determination, inflection, functional word determination, paraphrasing, etc.", "datetime": "Monday November 3 2019, 09:00 \u2013 12:30", "location": "Marriott Room 4", "link": "http://taln.upf.edu/pages/msr2019-ws/"}, {"title": "[W6] LOUHI 2019 The Tenth International Workshop on Health Text Mining and Information Analysis", "authors": null, "abstract": "The Tenth International Workshop on Health Text Mining and Information Analysis provides an interdisciplinary forum for researchers interested in automated processing of health documents.", "datetime": "Monday November 3 2019, 09:00 \u2013 12:30", "location": "Marriott Room 2", "link": "http://louhi2019.fbk.eu/"}, {"title": "[W7] DeepLo 2019 Deep Learning for Low-Resource Natural Language Processing", "authors": null, "abstract": "Deep Learning for Low-Resource Natural Language Processing is a workshop that will bring together experts in deep learning and natural language processing whose research focuses on learning with scarce data.", "datetime": "Monday November 3 2019, 09:00 \u2013 12:30", "location": "AWE 203\u2013205", "link": "https://sites.google.com/view/deeplo19/"}, {"title": "[W8] COIN COmmonsense INference in NLP", "authors": null, "abstract": "COmmonsense INference in NLP is a workshop that aims at bringing together researchers that are interested in modeling commonsense knowledge, developing computational models thereof, and applying commonsense inference methods in NLP tasks.", "datetime": "Monday November 3 2019, 09:00 \u2013 12:30", "location": "Marriott Ballroom A", "link": "http://www.coli.uni-saarland.de/~mroth/COIN/"}, {"title": "[W9] AnnoNLP Aggregating and analysing crowdsourced annotations for NLP", "authors": null, "abstract": "Aggregating and analysing crowdsourced annotations for NLP Although there is a large body of work analysing crowdsourced data, be that probabilistic or traditional, there has been less work devoted to NLP tasks. The aim of the proposed workshop is to bring together the community of researchers interested in this area.", "datetime": "Monday November 3 2019, 09:00 \u2013 12:30", "location": "Marriott Room 3", "link": "http://dali.eecs.qmul.ac.uk/annonlp"}, {"title": "[W10] MRQA The 2nd Workshop on Machine Reading for Question Answering", "authors": null, "abstract": "The 2nd Workshop on Machine Reading for Question Answering focuses on understanding and improving methods for question answering (QA) from the text. This year, the workshop will host a shared task on QA with an emphasis on generalization.", "datetime": "Monday November 4 2019, 09:00 \u2013 17:35", "location": "AWE 201B\u2013C", "link": "https://mrqa.github.io/"}, {"title": "[W11] BioNLP-OST 2019 International Workshop on BioNLP Open Shared Tasks 2019", "authors": null, "abstract": "International Workshop on BioNLP Open Shared Tasks 2019 is organized to facilitate development and sharing of computational tasks of biomedical text mining and solutions to them.", "datetime": "Monday November 4 2019, 09:00 \u2013 17:35", "location": "Marriott Room 2", "link": "http://2019.bionlp-ost.org"}, {"title": "[W12] WNGT The 3rd Workshop on Neural Generation and Translation", "authors": null, "abstract": "The 3rd Workshop on Neural Generation and Translation aims to provide a forum for research in applications of neural models to language generation and translation tasks.", "datetime": "Monday November 4 2019, 09:00 \u2013 17:35", "location": "AWE 201A (morning), Marriott Ballroom A (afternoon)", "link": "https://sites.google.com/view/wngt19/home"}, {"title": "[W13] W-NUT 2019 The 5th Workshop on Noisy User-generated Text", "authors": null, "abstract": "The 5th Workshop on Noisy User-generated Text focuses on Natural Language Processing applied to noisy user-generated text, such as that found in social media, online reviews, crowdsourced data, web forums, clinical records and language learner essays.", "datetime": "Monday November 4 2019, 09:00 \u2013 17:35", "location": "Marriott Ballroom A (morning), AWE 201A (afternoon)", "link": "http://noisy-text.github.io/"}, {"title": "[W14] NewSum The Workshop on New Frontiers in Summarization", "authors": null, "abstract": "The Workshop on New Frontiers in Summarization seeks to bring together researchers from a diverse range of fields (e.g., summarization, visualization, language generation, cognitive and psycholinguistics) for discussion on key issues related to automatic summarization.", "datetime": "Monday November 4 2019, 09:00 \u2013 17:35", "location": "Marriott Room 1", "link": "https://summarization2019.github.io/"}, {"title": "[W15] TextGraphs-19 Graph-based Methods for Natural Language Processing", "authors": null, "abstract": "Graph-based Methods for Natural Language Processing is a workshop series that publishes and promotes the synergy between the field of Graph Theory and Natural Language Processing.", "datetime": "Monday November 4 2019, 09:00 \u2013 17:35", "location": "AWE 203\u2013205", "link": "https://sites.google.com/view/textgraphs2019"}, {"title": "[W16] WAT2019 The 6th Workshop on Asian Translation", "authors": null, "abstract": "The 6th Workshop on Asian Translation is a new open evaluation campaign focusing on Asian languages.", "datetime": "Monday November 4 2019, 09:00 \u2013 17:35", "location": "AWE 202", "link": "http://lotus.kuee.kyoto-u.ac.jp/WAT/"}, {"title": "[W17] ECONLP 2019 The 2nd Workshop on Economics and Natural Language Processing", "authors": null, "abstract": "The 2nd Workshop on Economics and Natural Language Processing addresses the increasing relevance of natural language processing (NLP) for regional, national and international economy, both in terms of already operational language technology products and systems, as well as newly emerging methodologies and techniques reflecting the requirements at the intersection of economics and NLP.", "datetime": "Monday November 4 2019, 18:00 \u2013 20:00", "location": "Marriott Room 3", "link": "https://sites.google.com/view/econlp-2019"}, {"title": "[W18] NLP4IF NLP for Freedom: Censorship, Disinformation, and Propaganda", "authors": null, "abstract": "NLP for Freedom: Censorship, Disinformation, and Propaganda is a workshop dedicated to NLP methods that potentially contribute (either positively or negatively) to the free flow of information on the Internet, or to our understanding of the issues that arise in this area.", "datetime": "Monday November 4 2019, 18:00 \u2013 20:00", "location": "Marriott Room 4", "link": "http://www.netcopia.net/nlp4if/"}]}}